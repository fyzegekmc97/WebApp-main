{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/feyzi/.local/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/feyzi/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/feyzi/.local/lib/python3.10/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/feyzi/.local/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/feyzi/.local/lib/python3.10/site-packages (1.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/feyzi/.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.23.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/feyzi/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/feyzi/.local/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/feyzi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/feyzi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/feyzi/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/feyzi/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/feyzi/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 07:33:20.896333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-19 07:33:20.896391: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.load('images_combined_coordinator_train.npy')\n",
    "y_train = np.load('labels_combined_coordinator_train.npy')\n",
    "x_test = np.load('images_combined_coordinator_test.npy')\n",
    "y_test = np.load('labels_combined_coordinator_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.getsizeof(x_train))\n",
    "print(sys.getsizeof(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "no_users = 2\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train[0])\n",
    "print(\"-------\")\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 200*200*3))/255\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 200*200*3))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "K=8\n",
    "L=8\n",
    "M=8\n",
    "N=8\n",
    "s1 = 4\n",
    "s2 = 4\n",
    "numClasses = 2\n",
    "class User:\n",
    "    def __init__(self):\n",
    "        self.W1 = tf.Variable(tf.random.truncated_normal([s1,s2,3,K], stddev=0.1))\n",
    "        self.W2 = tf.Variable(tf.random.truncated_normal([s1,s2,K,L], stddev=0.1))\n",
    "        self.W3 = tf.Variable(tf.random.truncated_normal([s1,s2,L,M], stddev=0.1))\n",
    "        self.W4 = tf.Variable(tf.random.truncated_normal([50*50*M, N], stddev=0.1))\n",
    "        self.W5 = tf.Variable(tf.random.truncated_normal([N,numClasses], stddev=0.1))\n",
    "        \n",
    "        self.b1 = tf.Variable(tf.random.truncated_normal([K]))#tf.Variable(tf.ones([K])/10)\n",
    "        self.b2 = tf.Variable(tf.random.truncated_normal([L]))#tf.Variable(tf.ones([L])/10)\n",
    "        self.b3 = tf.Variable(tf.random.truncated_normal([M]))#tf.Variable(tf.ones([M])/10)\n",
    "        self.b4 = tf.Variable(tf.random.truncated_normal([N]))#tf.Variable(tf.ones([N])/10)\n",
    "        self.b5 = tf.Variable(tf.random.truncated_normal([numClasses]))#tf.Variable(tf.ones([numClasses])/10)\n",
    "        \n",
    "        self.gW1 = tf.Variable(tf.random.truncated_normal([s1,s2,3,K], stddev=0.1))\n",
    "        self.gW2 = tf.Variable(tf.random.truncated_normal([s1,s2,K,L], stddev=0.1))\n",
    "        self.gW3 = tf.Variable(tf.random.truncated_normal([s1,s2,L,M], stddev=0.1))\n",
    "        self.gW4 = tf.Variable(tf.random.truncated_normal([50*50*M, N], stddev=0.1))\n",
    "        self.gW5 = tf.Variable(tf.random.truncated_normal([N,numClasses], stddev=0.1))\n",
    "        \n",
    "        self.gb1 = tf.Variable(tf.random.truncated_normal([K]))#tf.Variable(tf.ones([K])/10)\n",
    "        self.gb2 = tf.Variable(tf.random.truncated_normal([L]))#tf.Variable(tf.ones([L])/10)\n",
    "        self.gb3 = tf.Variable(tf.random.truncated_normal([M]))#tf.Variable(tf.ones([M])/10)\n",
    "        self.gb4 = tf.Variable(tf.random.truncated_normal([N]))#tf.Variable(tf.ones([N])/10)\n",
    "        self.gb5 = tf.Variable(tf.random.truncated_normal([numClasses]))#tf.Variable(tf.ones([numClasses])/10)\n",
    "        \n",
    "    def neural_net(self, x):\n",
    "        C1 = tf.nn.conv2d(tf.reshape(x,[x.shape[0],200,200,3]), self.W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        y1 = tf.nn.relu(C1+self.b1)\n",
    "        C2 = tf.nn.conv2d(y1, self.W2, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        y2 = tf.nn.relu(C2+self.b2)        \n",
    "        C3 = tf.nn.conv2d(y2, self.W3, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        y3 = tf.nn.relu(C3+self.b3)         \n",
    "        YY=tf.reshape(y3, shape=[-1, 50*50*M])\n",
    "        \n",
    "        y4 = tf.nn.relu(tf.matmul(YY, self.W4)+self.b4)\n",
    "        ylogits = tf.matmul(y4, self.W5)\n",
    "        return tf.nn.softmax(ylogits+self.b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# mini-batch loss function.\n",
    "def mini_batches(X, Y, mb_size):\n",
    "\n",
    "    m = X.shape[0]\n",
    "    perm = list(np.random.permutation(m))\n",
    "    X_temp = X[perm,:]\n",
    "    Y_temp = Y[perm,:].reshape((m, Y.shape[1]))\n",
    "    \n",
    "    X_r = tf.convert_to_tensor(X_temp[0:mb_size,:], dtype=np.float32)\n",
    "    Y_r = tf.convert_to_tensor(Y_temp[0:mb_size,:], dtype=np.float32)\n",
    "    return X_r,Y_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cross-Entropy loss function.\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    # Compute cross-entropy.\n",
    "    return -tf.reduce_sum(y_true * tf.math.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Optimization process. \n",
    "def get_gradients(x, y, W1, W2, W3, W4, W5, b1, b2, b3, b4, b5):\n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = [W1, W2, W3, W4, W5, b1, b2, b3, b4, b5]\n",
    "    \n",
    "    with tf.GradientTape() as g:\n",
    "        C1 = tf.nn.conv2d(tf.reshape(x,[x.shape[0],200,200,3]), W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "        y1 = tf.nn.relu(C1+b1)\n",
    "        C2 = tf.nn.conv2d(y1, W2, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        y2 = tf.nn.relu(C2+b2)        \n",
    "        C3 = tf.nn.conv2d(y2, W3, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        y3 = tf.nn.relu(C3+b3)         \n",
    "        YY=tf.reshape(y3, shape=[-1, 50*50*M])\n",
    "        \n",
    "        y4 = tf.nn.relu(tf.matmul(YY, W4)+b4)\n",
    "        ylogits = tf.matmul(y4, W5)\n",
    "        pred = tf.nn.softmax(ylogits+b5)\n",
    "        loss = cross_entropy(pred, y) \n",
    "    \n",
    "    # Compute gradients.\n",
    "    gradients1, gradients2, gradients3, gradients4, gradients5, gradients_b1, gradients_b2, gradients_b3, gradients_b4, gradients_b5  = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    return gradients1, gradients2, gradients3, gradients4, gradients5, gradients_b1, gradients_b2, gradients_b3, gradients_b4, gradients_b5, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "users = [User() for i in range(no_users)]\n",
    "#rho = 20\n",
    "eta = 100\n",
    "central_modal = [tf.Variable(tf.random.truncated_normal([s1*s2*3*K,1], stddev=0.1)),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([s1*s2*K*L,1], stddev=0.1)),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([s1*s2*L*M,1], stddev=0.1)),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([50*50*M*N,1], stddev=0.1)),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([N*numClasses,1], stddev=0.1)),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([K])),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([L])),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([M])),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([N])),\\\n",
    "                 tf.Variable(tf.random.truncated_normal([numClasses]))]\n",
    "#print(central_modal[5].shape[0])\n",
    "#tf.Variable(tf.ones([K])),\\\n",
    "#                 tf.Variable(tf.ones([L])),\\\n",
    "#                 tf.Variable(tf.ones([M])),\\\n",
    "#                 tf.Variable(tf.ones([N])),\\\n",
    "#                 tf.Variable(tf.ones([numClasses]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_train_k = []\n",
    "y_train_k = []\n",
    "data_per_worker = int(x_train.shape[0]/no_users)\n",
    "for i in range(no_users):\n",
    "    first = i*data_per_worker\n",
    "    last = first + data_per_worker\n",
    "    x_train_k.append(x_train[first:last])\n",
    "    y_train_k.append(y_train[first:last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(type(x_train_k))\n",
    "print(len(x_train_k))\n",
    "print(x_train_k[0])\n",
    "print(x_train_k[0].shape)\n",
    "print(type(y_train_k))\n",
    "print(type(y_train_k[0]))\n",
    "print(y_train_k[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_test = tf.convert_to_tensor(x_test, dtype=np.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('CPU')\n",
    "print(\"Num CPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mb_size = 30\n",
    "n_iters = 300\n",
    "lr = 0.000001\n",
    "#n_localIter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Train_Acc = []\n",
    "Test_Acc = []\n",
    "acc_train = np.zeros([n_iters,1])\n",
    "acc_test = np.zeros([n_iters,1])\n",
    "total_loss = np.zeros([n_iters,1])\n",
    "\n",
    "for i in range(no_users):\n",
    "    users[i].W1.assign(tf.reshape(central_modal[0],[s1,s2,3,K]))\n",
    "    users[i].W2.assign(tf.reshape(central_modal[1],[s1,s2,K,L]))\n",
    "    users[i].W3.assign(tf.reshape(central_modal[2],[s1,s2,L,M]))\n",
    "    users[i].W4.assign(tf.reshape(central_modal[3],[50*50*M, N]))\n",
    "    users[i].W5.assign(tf.reshape(central_modal[4],[N,numClasses]))\n",
    "    \n",
    "    users[i].b1.assign(tf.reshape(central_modal[5],[K]))\n",
    "    users[i].b2.assign(tf.reshape(central_modal[6],[L]))\n",
    "    users[i].b3.assign(tf.reshape(central_modal[7],[M]))\n",
    "    users[i].b4.assign(tf.reshape(central_modal[8],[N]))\n",
    "    users[i].b5.assign(tf.reshape(central_modal[9],[numClasses]))\n",
    "    \n",
    "\n",
    "            \n",
    "for k in range(n_iters):               \n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for i in range(no_users):\n",
    "            batch_xx , batch_yy = mini_batches(x_train_k[i],y_train_k[i],  mb_size)\n",
    "            batch_x.append(batch_xx)\n",
    "            batch_y.append(batch_yy) \n",
    "        for i in range(no_users):\n",
    "\n",
    "            gradients1, gradients2, gradients3, gradients4, gradients5, gradients_b1, gradients_b2, gradients_b3, gradients_b4, gradients_b5, loss= get_gradients(batch_x[i], batch_y[i], users[i].W1,\\\n",
    "                                                                        users[i].W2, users[i].W3, users[i].W4, users[i].W5, users[i].b1, users[i].b2, users[i].b3, users[i].b4, users[i].b5)               \n",
    "                                           \n",
    "            users[i].gW1.assign(gradients1)\n",
    "            users[i].gW2.assign(gradients2)\n",
    "            users[i].gW3.assign(gradients3)\n",
    "            users[i].gW4.assign(gradients4)\n",
    "            users[i].gW5.assign(gradients5)\n",
    "            \n",
    "            users[i].gb1.assign(gradients_b1)\n",
    "            users[i].gb2.assign(gradients_b2)\n",
    "            users[i].gb3.assign(gradients_b3)\n",
    "            users[i].gb4.assign(gradients_b4)\n",
    "            users[i].gb5.assign(gradients_b5)\n",
    "            \n",
    "            \n",
    "            total_loss[k] = total_loss[k] + loss\n",
    "            \n",
    "        temp11 = 0\n",
    "        temp21 = 0\n",
    "        temp31 = 0 \n",
    "        temp41 = 0\n",
    "        temp51 = 0\n",
    "        \n",
    "        temp1_b = 0\n",
    "        temp2_b = 0\n",
    "        temp3_b = 0 \n",
    "        temp4_b = 0\n",
    "        temp5_b = 0\n",
    "        \n",
    "        for i in range(no_users):           \n",
    "            temp11 = temp11 + tf.reshape(users[i].gW1,[s1*s2*3*K,1])\n",
    "            \n",
    "            temp21 = temp21 + tf.reshape(users[i].gW2,[s1*s2*K*L,1]) \n",
    "                        \n",
    "            temp31 = temp31 + tf.reshape(users[i].gW3,[s1*s2*L*M,1]) \n",
    "            \n",
    "            temp41 = temp41 + tf.reshape(users[i].gW4,[50*50*M*N,1]) \n",
    "            \n",
    "            temp51 = temp51 + tf.reshape(users[i].gW5,[N*numClasses,1]) \n",
    "            \n",
    "            \n",
    "            temp1_b = temp1_b + users[i].gb1#tf.reshape(users[i].gb1,[K,1])\n",
    "            \n",
    "            temp2_b = temp2_b + users[i].gb2#tf.reshape(users[i].gb2,[L,1]) \n",
    "                        \n",
    "            temp3_b = temp3_b + users[i].gb3#tf.reshape(users[i].gb3,[M,1]) \n",
    "            \n",
    "            temp4_b = temp4_b + users[i].gb4#tf.reshape(users[i].gb4,[64,1]) \n",
    "            \n",
    "            temp5_b = temp5_b + users[i].gb5#tf.reshape(users[i].gb5,[10,1])\n",
    "            \n",
    "        central_modal[0] = central_modal[0]-1/(no_users)*lr*(temp11)\n",
    "        central_modal[1] = central_modal[1]-1/(no_users)*lr*(temp21)\n",
    "        central_modal[2] = central_modal[2]-1/(no_users)*lr*(temp31)\n",
    "        central_modal[3] = central_modal[3]-1/(no_users)*lr*(temp41)\n",
    "        central_modal[4] = central_modal[4]-1/(no_users)*lr*(temp51)\n",
    "        \n",
    "        central_modal[5] = central_modal[5]-1/(no_users)*lr*(temp1_b)\n",
    "        central_modal[6] = central_modal[6]-1/(no_users)*lr*(temp2_b)\n",
    "        central_modal[7] = central_modal[7]-1/(no_users)*lr*(temp3_b)\n",
    "        central_modal[8] = central_modal[8]-1/(no_users)*lr*(temp4_b)\n",
    "        central_modal[9] = central_modal[9]-1/(no_users)*lr*(temp5_b)\n",
    "        \n",
    "        #print(central_modal[5].shape[0])\n",
    "        #print(central_modal[5].shape[1])\n",
    "        \n",
    "        for i in range(no_users):\n",
    "                           \n",
    "            users[i].W1.assign(tf.reshape(central_modal[0],[s1,s2,3,K]))\n",
    "            users[i].W2.assign(tf.reshape(central_modal[1],[s1,s2,K,L]))\n",
    "            users[i].W3.assign(tf.reshape(central_modal[2],[s1,s2,L,M]))\n",
    "            users[i].W4.assign(tf.reshape(central_modal[3],[50*50*M, N]))\n",
    "            users[i].W5.assign(tf.reshape(central_modal[4],[N,numClasses]))\n",
    "            \n",
    "            users[i].b1.assign(tf.reshape(central_modal[5],[K]))\n",
    "            users[i].b2.assign(tf.reshape(central_modal[6],[L]))\n",
    "            users[i].b3.assign(tf.reshape(central_modal[7],[M]))\n",
    "            users[i].b4.assign(tf.reshape(central_modal[8],[N]))\n",
    "            users[i].b5.assign(tf.reshape(central_modal[9],[numClasses]))\n",
    "            \n",
    "        train_acc = []\n",
    "        test_acc = []\n",
    "        for j in range(no_users):  \n",
    "            train_pred = users[j].neural_net(batch_x[j])\n",
    "            train_acc.append(accuracy(train_pred, batch_y[j]))\n",
    "            test_pred = users[j].neural_net(x_test)\n",
    "            test_acc.append(accuracy(test_pred, y_test))\n",
    "        avgAcc_Train = np.mean(train_acc)\n",
    "        avgAcc_Test = np.mean(test_acc)\n",
    "        print('Train accuracy', avgAcc_Train)\n",
    "        print('Test accuracy',avgAcc_Test)\n",
    "        acc_train[k] = avgAcc_Train\n",
    "        acc_test[k] = avgAcc_Test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "acc_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create plots with pre-defined labels.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(n_iters), acc_train, 'r-*', label='Average Train Accuracy')\n",
    "ax.plot(range(n_iters), acc_test, 'b-*', label='Average Test Accuracy')\n",
    "\n",
    "legend = ax.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "np.save('acc_train_miniSGD', acc_train)\n",
    "np.save('acc_test_miniSGD', acc_test)\n",
    "np.save('loss_miniSGD', total_loss/no_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create plots with pre-defined labels.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(n_iters), total_loss/no_users, 'r-*', label='Average Loss')\n",
    "\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "The Jupyter notebook server failed to launch in time. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
